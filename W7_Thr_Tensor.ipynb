{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled56.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TF2 API 개요"
      ],
      "metadata": {
        "id": "RP-1QUg-0kKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorFlow2 API 알아보기"
      ],
      "metadata": {
        "id": "N4_qW0c90kRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 간단한 이미지 분류 문제를 풀어가면서 TensorFlow2(Tensorflow V2)를 활용한 모델링을 진행해 보겠다.\n",
        "\n",
        "TensorFlow2를 활용함에 있어 딥러닝 모델을 다양한 방법으로 작성할 수 있는데요. 이 부분이 처음 TensorFlow 및 딥러닝을 접하시는 분들에게는 큰 허들이 될 수 있다. '하나로 통일해서 하나만 공부하게 해주면 되지, 왜 이렇게 여러 개를 만들어서 고생을 시키지?'라는 생각을 허살 수도 있느데요. 처음에는 헷갈릴 수 있지만, 익숙해지시고 나면 경우에 따라 적합한 모델링 방식을 택해서 사용할 수 있다느 점에서 매우 강력하다고 느낄 수 있을 것이다.\n",
        "\n",
        "오늘 소개할 TensorFlow2에서 딥러닝 모델을 작성하는 방법에는 크게 3가지가 존재하는데요. 바로 Sequential, Functional, 그리고 Model subclassing이다. 아마 Sequential 모델은 이미 몇 번 사용해 보셔서 정확한 개념을 몰라도 익숙하실 것이다. Functional은 Sequential의 보다 일반화된 개념입니다. 그리고 Subclassing은 클래스로 구현된 기존의 모델을 상속받아 자신만의 모델을 만들어나가는 방식입니다. 세 가지 방법 모두 충분히 숙지하여 자유롭게 활용할 수 있게 되는 것이 중요하다."
      ],
      "metadata": {
        "id": "4TgDhjhX0kYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1)TensorFlow2 Sequential Model"
      ],
      "metadata": {
        "id": "6nSjvCOu0kcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(__넣고싶은 레이어__)\n",
        "\n",
        "model.add(__넣고싶은 레이어__)\n",
        "\n",
        "model.add(__넣고싶은 레이어__)\n",
        "\n",
        "model.fit(x, y, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "xSEWmd5y0kih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 자료에서 공부했던 모델은 대부분 위와 같은 형식이었다. model = kears.Sequential() 이라고 선언한 부분이 눈에 띄시나요?\n",
        "\n",
        "Sequential 모델을 활용하면 손쉽게 딥러닝 모델을 쌓아나갈 수 있다. 입력부터 출력까지 레이어를 그야말로 sequential하게 차곡차곡 add해서 쌓아나가기만 하면 된다. 무엇보다 이 방식은 초보자가 접근하기에 매우 쉽다는 장점이 있다. 그렇지만 모델의 입력과 출력이 여러개인 경우에는 적합하지 않은 모델링 방식이다. Sequential 모델은 반드시 입력 1가지, 출려 1가지를 전체로 한다.\n",
        "\n",
        "아래 참고 자료에서 Sequential Model로 작성한 모델의 전체 코드를 확인해 준다. 실습 세션에서 해당 모델링을 직접 진행해 볼 예정이다. "
      ],
      "metadata": {
        "id": "D8CIbP1N0km6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TensorFlow2 Function API"
      ],
      "metadata": {
        "id": "mxLcM8s50kp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "inputs = keras.Input(shape=(__원하는 입력값 모양__))\n",
        "\n",
        "x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(input)\n",
        "\n",
        "x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
        "\n",
        "outputs = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.fit(x,y, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "bGE_MLaf0kts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 위 Sequential Model을 활용하는 것과 다른 점은 바로 keras.Model을 사용한다는 점이다. 그래서 Sequential Model을 쓰는 것보다 더 일반적인 접근인 것이다. Sequential Model이란 사실 keras.Model을 상속받아 확장한 특수 사례에 불과하다. Functional API를 활용하면 앞서 배운 Sequential Model을 활용하는 것보다 더 자유로운 모델링을 진행할 수 있다. Functional이라는 뜻은 뭔가? 함수형으로 모델을 구성한다는 것, 즉 입력과 출력을 규정함으로써 모델 전체를 규정한다는 생각이다. 그래서 이번에는 Input이라는 것을 규정한다. input이 될 수 있는 텐서가 여러 개가 될 수도 있다. 그리고 레이어들을 자유롭게 엮어 출력(output)까지 규정하면 Model이란 바로 inputs와 outputs 만으로 규정된다. 정말 Functional하지 않나요 ?\n"
      ],
      "metadata": {
        "id": "ZuGBXUAn0kxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TensorFlow2 Subclassing"
      ],
      "metadata": {
        "id": "SdLu1a3e_W62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.__정의하고자 하는 레이어__()\n",
        "        self.__정의하고자 하는 레이어__()\n",
        "        self.__정의하고자 하는 레이어__()\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.__정의하고자 하는 레이어__(x)\n",
        "        x = self.__정의하고자 하는 레이어__(x)\n",
        "        x = self.__정의하고자 하는 레이어__(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "model = CustomModel()\n",
        "\n",
        "model.fit(x,y, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "pW0Tef3L_W-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막으로 Subclassing을 활용하면 제일 자유로운 모델리이을 진행할 수 있다. 사실 본질적으로는 Functional한 접근과 차이가 없다. 이것은 keras.Model을 상속받은 모델 클래스를 만드는 것이기 때문이다. 처음 만났던 Sequential Model도 따지고 보면 keras.Model을 상속받은 모델 클래스의 하나일 뿐이다. keras.Model은 위와 같이 __init__() 이라는 메서드 안에서 레이어 구성을 정의한다. 그리고 call()이라는 메서드 안에서 레이어 간 forward propagation을 구현한다. 이것으로 끝이다. 다만, 각 레이어에 대한 깊은 이해가 필요하고 초심자에게 의도치 않은 버그를 유발할 수 있따. 그렇지만, 여러분들이 공부해 나가시면서 복잡한 모델링을 진행하시게 되면 가장 많이 접하게 되실 모델링 스타일이기에 실습 세션에서 다뤄볼 예정이다."
      ],
      "metadata": {
        "id": "gov5JyYR_XBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorflow2 API로 모델 작성하기: MNIST (1) Sequential API 활용"
      ],
      "metadata": {
        "id": "ord6q7pU_XEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow2의 다양한 High-level API에 대해 둘러보았다. 그렇지만 아마도 직접 구현을 해보기 전에는 붕 뜬구름 같은 느낌이다. 그래서 우리는 앞서 본 TensorFlow2의 다양한 High-level API를 활용해서 이미지 문제를 풀어볼 예정이다.\n",
        "\n",
        "총 2가지의 문제를 3가지 AOI 모두를 활용하여 구현해 볼 예정이고, 이 과정은 최대한 여러분들 스스로 진행하는 것을 목표로 하자."
      ],
      "metadata": {
        "id": "vg1Ruksi_XH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-_QhpYdS-uTZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 구성부분\n",
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train=x_train[...,np.newaxis]\n",
        "x_test=x_test[...,np.newaxis]\n",
        "\n",
        "print(len(x_train), len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHMOmUJ5A_H-",
        "outputId": "67737541-0847-46d7-bbc2-73bd1f88125f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "60000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential Model을 구성해주세요.\n",
        "\"\"\"\n",
        "Spec:\n",
        "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "3. Flatten 레이어\n",
        "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
        "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
        "\"\"\"\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "gq36F_1qBNOv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 설정\n",
        "# 5 epochs 학습에 20분 정도 소요됩니다.\n",
        "# 잠시 스트레칭하고 휴식을 취해보아요~\n",
        "# (빠르게 동작 여부만 확인하고 싶으시면 epochs 값을 줄여주세요.)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZSqtwTfBNdk",
        "outputId": "376a1d1b-c25b-4d71-8e90-944517e7376d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 18s 3ms/step - loss: 0.1068 - accuracy: 0.9671\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0342 - accuracy: 0.9891\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0190 - accuracy: 0.9940\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0130 - accuracy: 0.9957\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0080 - accuracy: 0.9972\n",
            "313/313 - 1s - loss: 0.0524 - accuracy: 0.9875 - 828ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05244576930999756, 0.987500011920929]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorflow2 API로 모델 작성하기:MNIST (2) Functional API"
      ],
      "metadata": {
        "id": "bILBCsuiI8br"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에도 이전 스텝과 큰 차이가 없는 내용이다. 다만, 이번에는 keras.Model를 직접 활용하여야 하므로, keras.Input으로 정의된 iput 및 output 레이어 구성을 통해 model을 구현하셔야 한다."
      ],
      "metadata": {
        "id": "RystUFaEI8fL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4eDzdOgOJaxG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train=x_train[...,np.newaxis]\n",
        "x_test=x_test[...,np.newaxis]\n",
        "\n",
        "print(len(x_train), len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwKxVRfsJa0W",
        "outputId": "6da1dd40-700a-4554-a701-3fcb2a4921de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Spec:\n",
        "0. (28X28X1) 차원으로 정의된 Input\n",
        "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "3. Flatten 레이어\n",
        "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
        "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
        "x = keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(128, activation='relu')(x)\n",
        "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=predictions)"
      ],
      "metadata": {
        "id": "2_bV15TiJa3V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 설정\n",
        "# 5 epochs 학습에 20분 정도 소요됩니다.\n",
        "# 잠시 스트레칭하고 휴식을 취해보아요~\n",
        "# (빠르게 동작 여부만 확인하고 싶으시면 epochs 값을 줄여주세요.)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukrLQ3PHJvCE",
        "outputId": "d29cade7-13db-4ceb-c029-f8ab792b0428"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1076 - accuracy: 0.9664\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0345 - accuracy: 0.9885\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0197 - accuracy: 0.9936\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0128 - accuracy: 0.9960\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0092 - accuracy: 0.9969\n",
            "313/313 - 1s - loss: 0.0521 - accuracy: 0.9878 - 713ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05205900967121124, 0.9878000020980835]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "어떻습니까, 이번 스텝의 결과는 이전 스텝과 비교해 큰 차이가 나지 않는다는 것을 확인하셨나요?"
      ],
      "metadata": {
        "id": "LGtXagarI8mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorflow2 API로 모델 작성하기: MNIST (3) Subclassing"
      ],
      "metadata": {
        "id": "KRpB8AKeI8pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막으로 Subclassing 방법이다. keras.Model을 상속받은 클래스를 만드는 것이다. __init__() 메서드 안에서 레이어를 선언하고, call() 메서드 안에서 forward propagation을 구현하는 방식임을 기억하자. Functional 방식과 비교하자면, call()의 입력이 Input이고, call()의 리턴값이 Output이 되는 것이다."
      ],
      "metadata": {
        "id": "FSvHOWSCI8zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Ri5xFNTuBR0B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 구성부분\n",
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train=x_train[...,np.newaxis]\n",
        "x_test=x_test[...,np.newaxis]\n",
        "\n",
        "print(len(x_train), len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BuJCylIQBnW",
        "outputId": "c2148bb9-83a8-49dd-c031-3dc2af30abc5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subclassing을 활용한 Model을 구성해주세요.\n",
        "\"\"\"\n",
        "Spec:\n",
        "0. keras.Model 을 상속받았으며, __init__()와 call() 메서드를 가진 모델 클래스\n",
        "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "3. Flatten 레이어\n",
        "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
        "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
        "6. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
        "\"\"\"\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
        "        self.conv2 = keras.layers.Conv2D(64, 3, activation='relu')\n",
        "        self.flatten = keras.layers.Flatten()\n",
        "        self.fc1 = keras.layers.Dense(128, activation='relu')\n",
        "        self.fc2 = keras.layers.Dense(10, activation='softmax')\n",
        "        \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "model = CustomModel()"
      ],
      "metadata": {
        "id": "Xe96TxyLQEC3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 설정\n",
        "# 5 epochs 학습에 20분 정도 소요됩니다.\n",
        "# 잠시 스트레칭하고 휴식을 취해보아요~\n",
        "# (빠르게 동작 여부만 확인하고 싶으시면 epochs 값을 줄여주세요.)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7527_0MQQMqD",
        "outputId": "86a35d4d-e8e4-44d0-8f6c-9c6689458a7d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1063 - accuracy: 0.9673\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0352 - accuracy: 0.9888\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0201 - accuracy: 0.9933\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0133 - accuracy: 0.9958\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0095 - accuracy: 0.9969\n",
            "313/313 - 1s - loss: 0.0536 - accuracy: 0.9874 - 719ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05358916148543358, 0.9873999953269958]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorFlow2 API로 모델 작성 및 학습하기: CIFAR-100 (1)"
      ],
      "metadata": {
        "id": "h8582N9wR14i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "tH0hiFY8SINX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 구성부분\n",
        "cifar100 = keras.datasets.cifar100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "print(len(x_train), len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg4EfWNGSIQm",
        "outputId": "1d5282ca-7115-4538-8e58-56924f56e652"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 11s 0us/step\n",
            "169017344/169001437 [==============================] - 11s 0us/step\n",
            "50000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential Model을 구성해주세요.\n",
        "\"\"\"\n",
        "Spec:\n",
        "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "2. pool_size가 2인 MaxPool 레이어\n",
        "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "4. pool_size가 2인 MaxPool 레이어\n",
        "5. Flatten 레이어\n",
        "6. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
        "7. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
        "\"\"\"\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(16, 3, activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dense(100, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "WuKgLe3pSIVu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorflow2 API로 모델 작성 및 학습하기: CIFAR-100 (2) Functional API 활용"
      ],
      "metadata": {
        "id": "yiDpE0sgSk0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에도 이전 스텝과 큰 차이가 없는 내용이다. 다만, 이번에는 keras.Model을 직접 활용하여야 하므로, keras.Input으로 정의된 input 및 output 레이어 구성을 통해 model을 구현하셔야 한다."
      ],
      "metadata": {
        "id": "rJHAdE3mSvGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "R2KwQrIuSt7K"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar100 = keras.datasets.cifar100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "print(len(x_train), len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWEIsYTTS_Ix",
        "outputId": "4713c094-9d2b-4cd6-b34a-74e77a78550a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional API를 활용한 Model을 구성해주세요.\n",
        "\"\"\"\n",
        "Spec:\n",
        "0. (32X32X3) 차원으로 정의된 Input\n",
        "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "2. pool_size가 2인 MaxPool 레이어\n",
        "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "4. pool_size가 2인 MaxPool 레이어\n",
        "5. Flatten 레이어\n",
        "6. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
        "7. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
        "\"\"\"\n",
        "\n",
        "cifar100 = keras.datasets.cifar100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "print(len(x_train), len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDt8b6W6TBog",
        "outputId": "7d782291-1110-4e71-e236-61448f791d8e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 설정\n",
        "# 5 epochs 학습에 5분 정도 소요됩니다.\n",
        "# (빠르게 동작 여부만 확인하고 싶으시면 epochs 값을 낮게 설정해주세요.)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGx_2EePTH-J",
        "outputId": "ff0569b2-4148-4c13-8aa5-81394cc9b35c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6434 - accuracy: 0.1524\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.9418 - accuracy: 0.2753\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6258 - accuracy: 0.3377\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4144 - accuracy: 0.3821\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2462 - accuracy: 0.4178\n",
            "313/313 - 1s - loss: 2.6005 - accuracy: 0.3488 - 697ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.6004843711853027, 0.34880000352859497]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorflow2 API로 모델 작성 및 학습하기: CIFAR-100 (3) Subclassing 활용"
      ],
      "metadata": {
        "id": "Y6mGIOwUTUwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막으로 Subclassing 방법이다. keras.Model을 상속받은 클래스를 만드는 것이다. init() 메서드 안에서 레이어를 선언하고, call() 메서드 안에서 forward propagation을 구현하는 방식임을 기억해라. Functional 방식과 비교하자면, call()의 입력이 input이고, call()의 리턴값이 Output이 되는 것이다.\n",
        "\n",
        "여전히 정확도는 40% 미만의 수치일 텐데, 이번 스텝에서는 Subclassing과 함께, 그동안 배웠던 딥러닝 기법을 다양하게 적용해 보는 기회로 삼을 수 있길를 바란다."
      ],
      "metadata": {
        "id": "W_bphalCTegm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "M1FlHYlDTPoP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 구성부분\n",
        "cifar100 = keras.datasets.cifar100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "print(len(x_train), len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCIVyOwuUEID",
        "outputId": "8505222a-7295-45fb-e515-1fbf6b30b803"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subclassing을 활용한 Model을 구성해주세요.\n",
        "\"\"\"\n",
        "Spec:\n",
        "0. keras.Model 을 상속받았으며, __init__()와 call() 메서드를 가진 모델 클래스\n",
        "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "2. pool_size가 2인 MaxPool 레이어\n",
        "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
        "4. pool_size가 2인 MaxPool 레이어\n",
        "5. Flatten 레이어\n",
        "6. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
        "7. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
        "8. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
        "\"\"\"\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
        "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
        "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
        "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
        "        self.flatten = keras.layers.Flatten()\n",
        "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
        "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
        "        \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "model = CustomModel()"
      ],
      "metadata": {
        "id": "EyxOo6aTUG3w"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 설정\n",
        "# 5 epochs 학습에 5분 정도 소요됩니다.\n",
        "# (빠르게 동작 여부만 확인하고 싶으시면 epochs 값을 낮게 설정해주세요.)\n",
        "\n",
        "# 학습 관련 부분을 작성해주세요\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbWKHtBOURsa",
        "outputId": "d3ad79fe-2766-49b5-894f-aad8d249a386"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6269 - accuracy: 0.1582\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9471 - accuracy: 0.2784\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6413 - accuracy: 0.3371\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4235 - accuracy: 0.3823\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2414 - accuracy: 0.4221\n",
            "313/313 - 1s - loss: 2.6066 - accuracy: 0.3505 - 689ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.6066033840179443, 0.3504999876022339]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Tape의 활용"
      ],
      "metadata": {
        "id": "aJ2BeEU4Utro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automatic differentiation - GradientTape"
      ],
      "metadata": {
        "id": "w3HTxwIPUtvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리는 조금 전까지 아주 비슷한 테스크 2개를, 본질적으로 큰 차이가 없는 3개의 모델 구성 방법을 활용하여 딥러닝으로 구현해 보았다. 그 동안 완전히 동일하게 구성했던 것은 바로 아래와 같이 구성된 모델 학습 관련 부분이다."
      ],
      "metadata": {
        "id": "CzEayhCrUtyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    model.compile(optimizer='adam',\n",
        "\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "id": "OYvTOP3zUt2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numpy만 가지고 딥러닝을 구현하는 것을 회상해보자. model.fit()이라는 한 줄로 수행 가능한 딥러닝 모델 훈련 과정은 실제로는 어떠했나요 ?\n",
        "\n",
        "1. Forward Propagation 수행 및 중간 레이어값 저장\n",
        "2. Loss 값 계산\n",
        "3. 중간 레이어값 및 Loss를 활용한 체인룰(chain rule) 방식의 역전파(Backward Propagation) 수행\n",
        "4. 학습 파라미터 업데이트\n",
        "\n",
        "이상 4단계로 이루어진 train_step을 여러번 반복했다.\n",
        "\n",
        "이런 과정이 TF2 API에는 model.fit()이라는 메서드 안에 모두 추상화되어 감추어져 있습니다. \n",
        "\n",
        "Tensorflow에서 제공하는 tf.GradientTape는 위와 같이 순전파(forward pass)로 진행된 모든 연산의 중간 레이어값을 tape에 기록하고, 이를 이용해 gradient를 계산한 후 tape를 폐기하는 기능 수행한다. 그러면 아래에서는 이전 스텝에서 진행했던 학습을 tf.GradientTape를 이용한 것으로 변형해 보겠습니다. 아래에서 소개할 tf.GradientTape는 이후 그래디언트를 좀 더 고급스럽게 활용하는 다양한 기법을 통해 자주 만나게 될 것이다."
      ],
      "metadata": {
        "id": "M7VERJ2JUt53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 데이터 구성부분\n",
        "cifar100 = keras.datasets.cifar100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "print(len(x_train), len(x_test))\n",
        "\n",
        "# 모델 구성부분\n",
        "class CustomModel(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
        "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
        "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
        "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
        "        self.flatten = keras.layers.Flatten()\n",
        "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
        "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = CustomModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cENOQL1cWmhQ",
        "outputId": "80db5692-dc66-40ee-8474-184c1dddb1c9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기까지는 앞에서 다루었던 Subclassing을 활용한 모델 작성법과 전혀 다르지 않다. 달라지는 것은  model.compile(), model.fit()을 통해 손쉽게 진행했던 학습 세팅 및 수행 부분이다."
      ],
      "metadata": {
        "id": "2-N6FJ_FWtQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ke-zGzrXW51f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 모델 학습을 위해 loss, optimizer를 지정해 주면 내부적으로 매 스텝 학습이 진행될 때마다 발생하는 loss 및 그래디언트가 어떻게 학습 파라미터를 업데이트하게 되는 지를 지정해 주는 작업이 mode.compile() 안에서 자동으로 진행되었다. 아래 코드는 tape.gradient()를 통해 매 스텝 학습이 진행될 때마다 발생하는 그래디언트를 추출한 후 optimizer.apply_gradients()를 통해 발생한 그래디언트가 업데이트해야 할 파라미터 model.trainable_variables를 지정해 주는 과정을 기술한 것이다. "
      ],
      "metadata": {
        "id": "xkKufGEVXGSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# tf.GradientTape()를 활용한 train_step\n",
        "def train_step(features, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(features)\n",
        "        loss = loss_func(labels, predictions)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "wmE3FslIXysR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 매 스텝 진행되는 학습이 실제 동작이 train_step() 메서드를 구현되었다."
      ],
      "metadata": {
        "id": "GJ9nFtYJXxb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.fit(x_train, y_train, epochs=5, batch_size=32)"
      ],
      "metadata": {
        "id": "6DCkULH3YCt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def train_model(batch_size=32):\n",
        "    start = time.time()\n",
        "    for epoch in range(5):\n",
        "        x_batch = []\n",
        "        y_batch = []\n",
        "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
        "            x_batch.append(x)\n",
        "            y_batch.append(y)\n",
        "            if step % batch_size == batch_size-1:\n",
        "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
        "                x_batch = []\n",
        "                y_batch = []\n",
        "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
        "    print(\"It took {} seconds\".format(time.time() - start))\n",
        "\n",
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSyl7ZmwUYYN",
        "outputId": "74d86b4c-94af-4538-901f-8e704a4a9c79"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: last batch loss = 3.1209\n",
            "Epoch 1: last batch loss = 2.5510\n",
            "Epoch 2: last batch loss = 2.3424\n",
            "Epoch 3: last batch loss = 2.2501\n",
            "Epoch 4: last batch loss = 2.1251\n",
            "It took 81.60394239425659 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 model.fit()으로 위와 같이 한 줄로 간단하게 수행되던 실제 배치 학습 과정은 다름 아니라 매 스텝마다 위에서 구현했던 train_step()가 호출되는 과정으로 바꾸어 구현할 수 있다. model.fit() 호출 시에 결정되는 batch_size만 이번 스텝에서 결정해 주면 된다."
      ],
      "metadata": {
        "id": "B9AILcMOYG93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def train_model(batch_size=32):\n",
        "    start = time.time()\n",
        "    for epoch in range(5):\n",
        "        x_batch = []\n",
        "        y_batch = []\n",
        "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
        "            x_batch.append(x)\n",
        "            y_batch.append(y)\n",
        "            if step % batch_size == batch_size-1:\n",
        "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
        "                x_batch = []\n",
        "                y_batch = []\n",
        "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
        "    print(\"It took {} seconds\".format(time.time() - start))\n",
        "\n",
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaHHWvNRYv1r",
        "outputId": "7e5131ee-23e4-4e40-fc49-9ba607a242ee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: last batch loss = 1.8924\n",
            "Epoch 1: last batch loss = 1.7606\n",
            "Epoch 2: last batch loss = 1.7415\n",
            "Epoch 3: last batch loss = 1.6944\n",
            "Epoch 4: last batch loss = 1.6067\n",
            "It took 81.02636909484863 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "어떤가? 위에서 구현한 train_model() 메서드가 실은 우리가 그동안 사용했던 model.fit() 메서드와 기능적으로 같다는 것이 확인되는가?\n",
        "\n",
        "이렇듯 tf.GradientTape()를 활용하면 model.compile()과 model.fit() 안에 감추어져 있던 한 스텝의 학습 단계(위 예제에서는 train_step 메서드)를 끄집어내서 자유롭게 재구성할 수 있게 된다. 그동안 흔히 다루어 왔던 지도학습 방식과 다른 강화학습 또는 GAN(Generative Advasarial Network)의 학습을 위해서는 train_step 메서드의 재구성이 필수적이므로 tf.GradientTape()의 활용법을 꼭 숙지해야 한다."
      ],
      "metadata": {
        "id": "lT93tvUSY387"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
        "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
        "temp/len(y_test)  # Accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK__MR9UY8XY",
        "outputId": "3ec962a9-d06d-4f1d-e8e2-7411a644b043"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 357ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3321"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래디언트를 활용할 필요가 없는 evaluation 단계는 기존 model.predict() 메서드를 다시 활용하여 보았다. 충분한 성능을 확인할 수 있을 만큼의 학습이 진행된 상태가 아니니 최종 Accuracy 값은 신경 쓰지 않으셔도 무방하다.\n"
      ],
      "metadata": {
        "id": "7muN8Zy5ZK1h"
      }
    }
  ]
}